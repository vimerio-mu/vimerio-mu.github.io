<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Django学习笔记(1)</title>
    <link href="/2020/06/20/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)/"/>
    <url>/2020/06/20/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是Django"><a href="#什么是Django" class="headerlink" title="什么是Django"></a>什么是Django</h1><ul><li>一个web框架<ul><li>可用其快速开发网站</li><li>基于python</li></ul></li><li>“for perfectionsists”<ul><li>安全性高</li><li>可拓展性强</li></ul></li><li>with ddl<ul><li>开发速度较快</li><li>代码量较小，轻量化</li></ul></li></ul><h1 id="Django环境搭建"><a href="#Django环境搭建" class="headerlink" title="Django环境搭建"></a>Django环境搭建</h1><ol><li>python环境（官网下载即可）</li><li>Django环境（pip install django==版本）</li></ol><h1 id="Django基本操作"><a href="#Django基本操作" class="headerlink" title="Django基本操作"></a>Django基本操作</h1><h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><pre><code>django-admin startproject &lt;项目名&gt;</code></pre><p>生成一个项目文件夹，其下包含一个项目文件夹和一个配置文件manage.py</p><p>项目文件夹下包含四个文件：</p><ol><li>init：python中的固定文件，说明这是一个包，可以被其他程序调用</li><li>setting：Django项目的管理文件</li><li>urls：整个网站的路由控制，整个网站的url，规定哪些url可以访问</li><li>wsgi：部署时需要用到的文件</li></ol><h2 id="响应请求"><a href="#响应请求" class="headerlink" title="响应请求"></a>响应请求</h2><h3 id="如何打开网址？"><a href="#如何打开网址？" class="headerlink" title="如何打开网址？"></a>如何打开网址？</h3><p>这个过程本质上是由客户端向urls发送打开网址的请求，如果网址有效，urls分析网址并整合相关资源，处理请求，响应请求，返回相关内容。这是通过http协议实现的。</p><h3 id="打开网址的方法："><a href="#打开网址的方法：" class="headerlink" title="打开网址的方法："></a>打开网址的方法：</h3><h4 id="写响应内容"><a href="#写响应内容" class="headerlink" title="写响应内容"></a>写响应内容</h4><p>首先在urls.py中import了path方法，path方法返回一个对象（list）放入urlpatterns中</p><pre><code>path(&#39;网址&#39;,调用方法)</code></pre><p>新建views.py,首先</p><pre><code class="python">from django.http import HttpResponse</code></pre><p>然后定义一个方法</p><pre><code class="python">def index(request):    return HttpResponse(&quot;Hello World&quot;)</code></pre><p>这其中HttpResponse是一个函数，可以返回内容给网址，即返回给request</p><h4 id="添加到urls中"><a href="#添加到urls中" class="headerlink" title="添加到urls中"></a>添加到urls中</h4><p>首先在urls.py中先 引入views.py</p><pre><code class="python">from . import views#.表示同级目录</code></pre><p>然后添加新的网址和写好的响应内容</p><pre><code>path(&#39;&#39;,views.index)#什么都不写，就是主页（直接访问）</code></pre><h4 id="启动网站"><a href="#启动网站" class="headerlink" title="启动网站"></a>启动网站</h4><p>进入到项目文件夹下，使用命令行输入</p><pre><code>python manage.py runserver</code></pre><p>如果端口未被占用，则自动将项目部署到本地端口<a href="http://127.0.0.1:8000/，此时就可以访问网址了。正常情况下请求码应为200，若网址错误则返回404，若出现用户错误等其它错误，则返回500。" target="_blank" rel="noopener">http://127.0.0.1:8000/，此时就可以访问网址了。正常情况下请求码应为200，若网址错误则返回404，若出现用户错误等其它错误，则返回500。</a></p><p>总而言之，只有200的时候才可以正常打开网址。</p><p>Django3的版本好像没有了re_path方法了，现在只能用path。</p><h2 id="创建超级用户（管理员）"><a href="#创建超级用户（管理员）" class="headerlink" title="创建超级用户（管理员）"></a>创建超级用户（管理员）</h2><p>进入<a href="http://127.0.0.1:8000/admin，可以看到用户登录界面，此时我们可以在本机创建超级用户。" target="_blank" rel="noopener">http://127.0.0.1:8000/admin，可以看到用户登录界面，此时我们可以在本机创建超级用户。</a></p><p>你需要先用ctrl+c退出当前环境使命令行可操作，你可以用</p><pre><code>python manage.py help</code></pre><p>来查看自己可以使用的方法</p><p>首先必须为项目创建一个数据库才能让项目有所谓“后台”，自然才能有管理员</p><pre><code>python manage.py migrate</code></pre><p>自动在本地生成一个sqlit3的数据库</p><p>然后在用</p><pre><code>pyhon manage.py creatsuperuser</code></pre><p>创建超级用户，输入username和password之后就可以使用，可以不用输入email，即使你的password被提示太简单，你也可以继续使用例如root这样的弱智密码。</p><h2 id="更改网站默认语言"><a href="#更改网站默认语言" class="headerlink" title="更改网站默认语言"></a>更改网站默认语言</h2><p>Django默认的语言是英语（废话），但是你也可以修改为中文，看着舒服点。</p><p>你可以在setting.py下找到LANGUAGE_CODE 这一项，并将其改为</p><pre><code>LANGUAGE_CODE = &#39;zh-Hans&#39;</code></pre><p>Hans表示简体中文，Hant表示繁体中文。</p><h1 id="app相关"><a href="#app相关" class="headerlink" title="app相关"></a>app相关</h1><h2 id="为何要创建基本app"><a href="#为何要创建基本app" class="headerlink" title="为何要创建基本app"></a>为何要创建基本app</h2><p>在网站中，存在很多需要批量重复的内容块：比如在个人博客中，这个内容块可能是文章；在电商网站中，这个内容块可能是具体的商品。在需要批量重复内容块时，有一定的模型可以让我们的开发更加快速。在Django中，这样的内容模型被称为app。</p><h2 id="如何创建app"><a href="#如何创建app" class="headerlink" title="如何创建app"></a>如何创建app</h2><pre><code>python manage.py startapp &lt;应用名称&gt;</code></pre><p>startapp顾名思义就是创建一个app，执行后会在项目文件夹下生成一个名为应用名称的文件夹，下面包含一系列的东西：</p><ol><li>init：与上文一致</li><li>models：即模型，在其中定义具体的模型内容，用class类来定义</li></ol><p>下面来具体讲一下如何定义模型</p><h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><p>进入models.py，定义新的类，注意要继承模型类</p><pre><code class="python">class &lt;aritcla&gt;  (models.Model):    title = models.CharField(max_length=30)    content = models.TextField()</code></pre><p>学过数据库的同学应该都知道类似的操作，class就像定义一个关系，其中有很多个属性，每个属性有一个域，这里域就用字段类型来定义，其实整体结构和sql语句类似。sql语句中创建表的操作案例如下：</p><pre><code class="sql">CREATE TABLE 花卉           (花卉编号 char(8) PRIMARY KEY,            花卉名称 char(20),            单价 Numeric(8,2),            库存量 int,            );</code></pre><p>可以看出二者的操作极其相似，你也可以把模型理解成一个二维表。比如article这个模型拥有content和title两个属性，goods这个模型拥有name和price两个属性这样。当然，一个模型不一定只来源于一张表，也可以来自多张表。</p><h2 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h2><p>在写好模型之后，我们并不能直接的使用模型，我们必须注册该应用，表示我们会使用该应用，然后将其同步到我们的数据库中。还记得我们创建数据库的指令码？migrate，即迁移，我们必须把我们创建的模型同步到数据库中，这样我们才能在网站上使用它。这时候我们首先在全局设置文件setting中找到installed_app,在列表中将我们的app写入，然后执行以下命令</p><pre><code>python manage.py makemigrations #制造迁移python manage.py migrate #正式迁移</code></pre><p>若在你的models.py中没有语法错误等，你就可以正确的create并且apply你的应用，但这时候我们还是不能在网站的admin中找到我们的应用。因为我们只是<strong>CREAT</strong>和<strong>APPLY</strong>了这个app，还没有<strong>REGISTER</strong>这个app。我们需要打开应用文件夹下的admin.py来注册我们的应用。</p><p>首先我们需要引入我们的模型到admin.py中,然后注册我们的模型。</p><pre><code class="python">from .models import Articleadmin.site.register(Article)</code></pre><p>此时，我们就可以在网站的控制后台找到我们的模型了，并且自由的使用了。使用当然也很方便，直接添加就可以了，当然由于我们前面所指定的属性都没有允许空值的存在，所以这里你必须title和content都要有内容。</p><h2 id="显示内容"><a href="#显示内容" class="headerlink" title="显示内容"></a>显示内容</h2><p>如果我们想要在网站中显示我们的模板内容，我们首先要给出一个url来存放我们的内容。而正如我们在为何要创建app中所说，我们创建app就是为了减少重复操作，如果全部手动创建url对我们来说肯定是无法接受的，所以我们就需要一个自动获取对象的方法。</p><p>有相关知识的人应该都想到了，除了title和content以外，我们的article这个app还应该拥有一个类似于id的东西方便我们检索。是的，在迁移到数据库中时，系统已经自动为我们创建了自动增长的主键id，你可以在migration文件夹下找到py文件自己查看。（毕竟sqlite3是一个关系数据库，title和content不一定能成为主键，它就自己创建了一个主键）</p><p>有了这个id，我们就可以方便的展示和查询我们的article了。</p><p>而之后的操作就类似与 响应请求 中的操作，先定义一个方法，再在某个具体的url中调用方法展示内容。</p><hr><p>比如这里我们在app文件夹下的views.py中定义如下方法：</p><pre><code class="python">def article_detail(request,article_id):    return HttpResponse(&#39;文章id为: %s&#39; % article_id)</code></pre><p>这样我们就可以返回文章的id</p><p>然后再回到全局的urls.py中</p><pre><code>path(&#39;article/&lt;int:article_id&gt;&#39;,aritcle_detail,name=&#39;1&#39;),</code></pre><p>就可以在<a href="http://127.0.0.1:8000/article/122这样的url看到内容了。" target="_blank" rel="noopener">http://127.0.0.1:8000/article/122这样的url看到内容了。</a></p><p>当然，聪明的人应该已经发现问题了——这个东西并没有真正的调用app…因为我们根本没有122之多的文章，这是一个假的东西，只不过是获得了你输入的id并且在页面中显示…</p><hr><p>要想要获得app中的内容，我们当然要首先引入模型</p><p>在app文件夹下的views.py中</p><pre><code class="python">from .models import Article</code></pre><p>然后通过app.objects.get这一方法通过某些条件获得模型，将模型存入一个对象中,并且检索其中的属性值返回</p><pre><code class="python">def article_detail(request,article_id):    article = Article.objects.get(id = article_id)    return HttpResponse(&#39;文章标题为: %s 文章内容为: %s&#39; % (article.title, article.content))</code></pre>]]></content>
    
    
    <categories>
      
      <category>web</category>
      
    </categories>
    
    
    <tags>
      
      <tag>-前端</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何做一个还能看的个人博客(1)</title>
    <link href="/2020/04/20/%E5%A6%82%E4%BD%95%E5%81%9A%E4%B8%80%E4%B8%AA%E8%BF%98%E8%83%BD%E7%9C%8B%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2(1)/"/>
    <url>/2020/04/20/%E5%A6%82%E4%BD%95%E5%81%9A%E4%B8%80%E4%B8%AA%E8%BF%98%E8%83%BD%E7%9C%8B%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2(1)/</url>
    
    <content type="html"><![CDATA[<h2 id="项目起因"><a href="#项目起因" class="headerlink" title="项目起因"></a>项目起因</h2><p>因为想把自己之前做的东西弄成DD-center那样的网页，所以想学一些前端。<del>对我知道这个理由很扯淡</del>，但是我的确这段时间都在学前端，算是把html和css的基础技能都学了一遍吧，一些静态的网页应该是可以做了，<del>可以开始制造电子垃圾了</del>。接下来就要接着学JavaScript和一些框架（比如jQuery和vue.js之类的）了。但在这之前，先来检验一下我前面的学习成果。</p><h2 id="项目设计"><a href="#项目设计" class="headerlink" title="项目设计"></a>项目设计</h2><p>作为一个普通的个人博客，首先要有首页、功能页（个人介绍、标签归总等）、文章详情页三个部分。</p><p>在首页，我希望有一个包含logo和功能页的侧边栏，一个包含文章标题和内容简介的文章列表栏。</p><p>在功能页和详情页，我希望沿用主页的基本设计。对于功能页需要包含一些ui可以跳转到B站等网站中我的个人首页；对于文章页，就正常的沿用我md文件的排版就好。</p><p>在想清楚整个网站的构造之后，让我们进入具体的设计。</p><h4 id="首页设计"><a href="#首页设计" class="headerlink" title="首页设计"></a>首页设计</h4><pre><code class="html">&lt;!DOCTYPE html&gt;&lt;html&gt;    &lt;head&gt;        &lt;meta charset=&quot;utf-8&quot; /&gt;        &lt;title&gt;vimerio&#39;s blog&lt;/title&gt;        &lt;link href=&quot;https://cdn.bootcss.com/normalize/8.0.1/normalize.min.css&quot; rel=&quot;stylesheet&quot;&gt;        &lt;link rel=&quot;stylesheet&quot; href=&quot;./css/main.css&quot;/&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div class=&quot;side-bar&quot;&gt;        &lt;/div&gt;        &lt;div class=&quot;main&quot;&gt;        &lt;/div&gt;    &lt;/body&gt;&lt;/html&gt;</code></pre><p>首先我们设计两个div，分别是side-bar（侧边栏）和main（主要部分即文章列表）。</p><p>在接着介绍之前，我提一下normalize.css这个css文件，这是一个比较通用的初始化css文件，包括但不限于取消body的margin等等，可以达到很好的初始化效果，提升效率必备（<del>懒狗必备</del>）。</p><p>在设计完第一级的标签之后，我们再设计二级和三级标签。</p><pre><code class="html">&lt;div class=&quot;side-bar&quot;&gt;            &lt;div class=&quot;header&quot;&gt;                &lt;a class=&quot;logo&quot;href=&quot;index.html&quot;&gt;&lt;img src=&quot;./img/678.png&quot;&gt;&lt;/a&gt;                &lt;div class=&quot;intro&quot;&gt;&lt;b&gt;WHU SIM freshman&lt;/b&gt;&lt;br/&gt;                &lt;b&gt; learning field:Data Visualization&lt;/b&gt;&lt;br /&gt;                &lt;b&gt;field:NLP&lt;/b&gt;&lt;/div&gt;            &lt;/div&gt;            &lt;div class=&quot;nav&quot;&gt;                &lt;a href=&quot;#&quot; class=&quot;item&quot;&gt;关于我&lt;/a&gt;                &lt;a href=&quot;#&quot; class=&quot;item&quot;&gt;联系我&lt;/a&gt;                &lt;a href=&quot;#&quot; class=&quot;item&quot;&gt;捐赠&lt;/a&gt;            &lt;/div&gt;            &lt;div class=&quot;tag-list&quot;&gt;                &lt;a href=&quot;#&quot; class=&quot;item&quot;&gt;#python&lt;/a&gt;                &lt;a href=&quot;#&quot; class=&quot;item&quot;&gt;#html&lt;/a&gt;                &lt;a href=&quot;#&quot; class=&quot;item&quot;&gt;#tensorflow&lt;/a&gt;            &lt;/div&gt;        &lt;/div&gt;        &lt;div class=&quot;main&quot;&gt;            &lt;div class=&quot;article-list&quot;&gt;                &lt;div class=&quot;item&quot;&gt;                    &lt;a href=&quot;article.html&quot; class=&quot;title&quot;&gt;lorem&lt;/a&gt;                    &lt;div class=&quot;status&quot;&gt;2020-4-1 |标签：#python&lt;/div&gt;                    &lt;div class=&quot;content&quot;&gt;orem&lt;/div&gt;                &lt;/div&gt;            &lt;/div&gt;        &lt;/div&gt;    &lt;/body&gt;</code></pre><p>我在侧边栏中设计了导航栏（nav）和标签索引（tag-list），并且在其下用a标签整了一些超链接。</p><p>在文章列表中定义了item用来存放单个的文章介绍，并且设置了标题（一个可点击的超链接），状态（如你所见：发布时间，标签）。在这之后，我们就可以开始css的设计了。</p><pre><code class="css">body {    background: #454545;    line-height: 1.7;}/*设置整个页面的底色和基本行高（说实话行高1真的太挤了）*/.side-bar{    float: left;    width: 20%;    position: fixed;    box-shadow: 0 0 5px 2px rgba(0,0,0,0.2);    background-color: #555;}/*我习惯所有div都设置成浮动左，然后侧边栏因为东西比较少就20%的宽度就好；因为我希望侧边栏无论何时都可以显示出来，让用户看比较长的文章的时候也可以看到，于是就设置成了fixed；阴影是模仿卡片的设计，这个网页主要都是卡片式设计。*/.side-bar &gt;* {    padding: 10px 15px;}/*&gt;*是表达所有子元素的写法，这样可以比较方便的同时设计nav和tag-list。在这里设置了一下他们之间的距离，这样看起来不会那么挤。*/.main {    float: right;    width: 80%;    color: #454545;}/*文章列表的浮动、宽度、字体颜色。*/img {    width: 220px;    height: 200px;    border-radius: 50%;}/*logo这里就简单整一下长和宽，并且做成圆形（其实是椭圆）*/a,body{    color:snow ;}/*要设置多个标签的时候用逗号就可以了。*/a {    text-decoration: none;}/*取消下划线*/.nav a,.tag-list a {    display: block;    padding: 5px;    color: #888;    -webkit-transition: color 200ms;    -moz-transition:color 200ms ;    -ms-transition:color 200ms ;    -o-transition:color 200ms ;    transition: color 200ms;}/*这里做了一下字体颜色渐变，这样看起来就没那么突兀。可以用transition+tab快速打出上面的东西*/.nav a:hover,.tag-list a:hover {    color: snow;}/*设置hover（点击时）的颜色。*/.nav a {    font-weight: 700;}/*加粗导航栏字体*/.article-list,.article {    margin-right: 30%;    background: #FFFAFA;    padding: 20px 30px;    box-shadow: 0 0 5px 2px rgba(0,0,0,0.2);}/*同样的给文章列表做卡片效果和底色以及间距的设置。其实说实话底色那么暗卡片挺难看出来的不过前面弄了复制一下也方便*/.title {    font-size:22px;    font-weight: 700;    color: #454545;}/*标题加大加粗改色*/.status {    font-size: 13px;    color: #ccc;}/*状态比较不重要，字体小一点颜色浅一点*/item &gt;* {    margin: 10px 0;}/*同样的用&gt;*定义所有子元素，设置内上下边距*/.article-list.item {    margin-bottom: 25px;}/*底部不要靠太近*/</code></pre><p>效果如下：<a href="http://q8i78k1ua.bkt.clouddn.com/html.jpg" target="_blank" rel="noopener">http://q8i78k1ua.bkt.clouddn.com/html.jpg</a></p><h4 id="文章详情页设计"><a href="#文章详情页设计" class="headerlink" title="文章详情页设计"></a>文章详情页设计</h4><p>在这里推荐一下我现在用markdown编辑器Typora，清爽免费业界清流（<del>结一下</del>）。这个软件有一个md转html的功能。于是我的文章详情页设计还没有开始就结束了…</p><h4 id="导航栏和标签集合"><a href="#导航栏和标签集合" class="headerlink" title="导航栏和标签集合"></a>导航栏和标签集合</h4><p>下次再更，下次一定</p>]]></content>
    
    
    <categories>
      
      <category>web</category>
      
    </categories>
    
    
    <tags>
      
      <tag>-html -css</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>爬取用户关注者并生成其粉丝数和播放数图表</title>
    <link href="/2020/04/07/%E7%88%AC%E5%8F%96%E7%94%A8%E6%88%B7%E5%85%B3%E6%B3%A8%E8%80%85%E5%B9%B6%E7%94%9F%E6%88%90%E5%85%B6%E7%B2%89%E4%B8%9D%E6%95%B0%E5%92%8C%E6%92%AD%E6%94%BE%E6%95%B0%E5%9B%BE%E8%A1%A8/"/>
    <url>/2020/04/07/%E7%88%AC%E5%8F%96%E7%94%A8%E6%88%B7%E5%85%B3%E6%B3%A8%E8%80%85%E5%B9%B6%E7%94%9F%E6%88%90%E5%85%B6%E7%B2%89%E4%B8%9D%E6%95%B0%E5%92%8C%E6%92%AD%E6%94%BE%E6%95%B0%E5%9B%BE%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="项目起因"><a href="#项目起因" class="headerlink" title="项目起因"></a>项目起因</h2><p>其实我从很久之前看了B站相关的数据可视化视频之后就很想尝试一下，但是一直没有动力。正好最近在推vtuber，想着为圈子做些贡献，并且WHUer无学可上，闲着也是闲着。我就自学了一些网络爬虫和数据可视化，虽然不多但是勉强够用，于是就开始了这个项目。</p><h2 id="项目设计"><a href="#项目设计" class="headerlink" title="项目设计"></a>项目设计</h2><p>简单的来说这个项目可以分成三个部分：</p><h4 id="1-根据uid访问用户关注页并获得其关注者的信息（uid）"><a href="#1-根据uid访问用户关注页并获得其关注者的信息（uid）" class="headerlink" title="1.根据uid访问用户关注页并获得其关注者的信息（uid）"></a>1.根据uid访问用户关注页并获得其关注者的信息（uid）</h4><h4 id="2-根据获得的up主uid逐一访问他们的粉丝页并且找到粉丝数和播放量的api"><a href="#2-根据获得的up主uid逐一访问他们的粉丝页并且找到粉丝数和播放量的api" class="headerlink" title="2.根据获得的up主uid逐一访问他们的粉丝页并且找到粉丝数和播放量的api"></a>2.根据获得的up主uid逐一访问他们的粉丝页并且找到粉丝数和播放量的api</h4><h4 id="3-整理数据并制作图表"><a href="#3-整理数据并制作图表" class="headerlink" title="3.整理数据并制作图表"></a>3.整理数据并制作图表</h4><p>下面我来分别介绍项目的三个部分。</p><h2 id="项目实现"><a href="#项目实现" class="headerlink" title="项目实现"></a>项目实现</h2><h4 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h4><p>之前我们已经实现了根据uid获得用户简介和名称。其实原理完全一样，只不过换了网页。但是不同之处在于这里我们要用selenium来模拟浏览器，不然无法看到相关信息。</p><pre><code class="python">from selenium import webdriverfrom bs4 import BeautifulSoupimport reuser=input(&#39;请输入你的uid号：&#39;)uid_href=&#39;&#39;href=[]driver=webdriver.Firefox()driver.get(&#39;https://space.bilibili.com/&#39;+user+&#39;/fans/follow&#39;)html=driver.page_sourcesoup=BeautifulSoup(html,&#39;html.parser&#39;)tags=soup.find_all(attrs={&#39;href&#39;:re.compile(r&quot;//space.bilibili.com/(\d+)/&quot;)})for tag in tags:    if &#39;href&#39; in tag.attrs:        href+=tag.attrs[&#39;href&#39;]    uid_href=&#39;&#39;.join(href)pattern=re.compile(r&#39;\d+&#39;)uids=pattern.findall(uid_href)uids=list(set(uids))</code></pre><h4 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h4><p>这一步我们要获得up主的粉丝数和播放数。如果尝试过你就会发现：这两个数据不是静态的存在于当前页面的源代码中的，而是有一个api将数据传给当前页面的。我们经过观察可以发现API的url分别为：</p><p>‘<a href="https://api.bilibili.com/x/relation/stat?vmid=’+uid" target="_blank" rel="noopener">https://api.bilibili.com/x/relation/stat?vmid=’+uid</a>     (粉丝)</p><p>和</p><p>‘<a href="https://api.bilibili.com/x/space/upstat?mid=&#39;+uid" target="_blank" rel="noopener">https://api.bilibili.com/x/space/upstat?mid=&#39;+uid</a>  （播放）</p><p>接下来我们就获得里面的数据并存为列表就可以了。</p><pre><code class="python">#获得粉丝数followers=[]for i in range(0,len(uids)):    driver.get(&#39;https://api.bilibili.com/x/relation/stat?vmid=&#39;+uids[i])    html=driver.page_source    soup=BeautifulSoup(html,&#39;html.parser&#39;)    data=soup.find(&#39;div&#39;,id=&#39;json&#39;)    data=data.string    data=data.split(&#39;&quot;follower&quot;:&#39;)    follower=data[-1].split(&#39;}}&#39;)    followers+=follower    followers= [i for i in followers if i != &#39;&#39;]#获得播放量views=&#39;&#39;  for i in range(0,len(uids)):    driver.get(&#39;https://api.bilibili.com/x/space/upstat?mid=&#39;+uids[i])    html=driver.page_source    soup=BeautifulSoup(html,&#39;html.parser&#39;)    data=soup.find(&#39;div&#39;,id=&#39;json&#39;)    data=data.string    data=data.split(&#39;{&quot;code&quot;:0,&quot;message&quot;:&quot;0&quot;,&quot;ttl&quot;:1,&quot;data&quot;:{&quot;archive&quot;:{&quot;view&quot;:&#39;)    data=data[1]    data=data.split(&#39;},&quot;article&quot;&#39;)    view=data[0]+&#39;,&#39;    views+=viewviews=views.split(&#39;,&#39;)</code></pre><p>当然为了制作包含名字而不是uid的图表，我们还需要获得up主的名称，这里可以直接用到上一篇文章的代码，这里就不再展示。</p><h4 id="第三部分"><a href="#第三部分" class="headerlink" title="第三部分"></a>第三部分</h4><p>最后我们制作图表就可以了，这里我们使用的是echarts的python版本pyecharts，这个工具可以生成动态图标而且有多个主题可以直接使用，很方便。</p><pre><code class="python">from pyecharts import options as optsfrom pyecharts.charts import Barfrom pyecharts.globals import ThemeTypec = (    Bar(init_opts=opts.InitOpts(theme=ThemeType.LIGHT))    .add_xaxis(name)    .add_yaxis(&quot;粉丝数量&quot;, followers)    .add_yaxis(&quot;播放量&quot;, views)    .set_global_opts(        xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=60)),        title_opts=opts.TitleOpts(title=&quot;hololive&quot;, subtitle=&quot;粉丝数和播放量&quot;),    )    .render(&quot;hololive.html&quot;))</code></pre><p>至此，项目全部完成，效果如下：</p><p><a href="http://q8i78k1ua.bkt.clouddn.com/hololive.html" target="_blank" rel="noopener">hololive20位vtuber的粉丝数和播放数图表</a></p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>其实我开始项目的五天前还完全不会任何爬虫，也不会数据可视化。学习并做到这些东西我拢共用了可能不到20个小时。这当然不是我有天分什么的。ted有一个演讲叫’<strong>How To Learn Anything You Want In Just 20 Hours</strong>‘，当然前提是1. Deconstruct the skill 2. Learn Enough to Self-Correct 3. Remove Practice Barriers 4. Practice at least 20 hours。</p><p>我觉得编程十分符合这些：1.编程的代码实现调用了许多第三方库，这些第三方库实际帮助你知道了代码的功能区块，帮助你分解了任务。2.代码的实现与否清晰可见。3.我用手机看视频，用电脑写代码，根本没有其他电子设备让我分神了…可能这就是我这段时间执行力比较高的原因吧。</p><h2 id="代码展示（以爬取hololive为例）"><a href="#代码展示（以爬取hololive为例）" class="headerlink" title="代码展示（以爬取hololive为例）"></a>代码展示（以爬取hololive为例）</h2><pre><code class="python">from selenium import webdriverimport requestsimport seleniumfrom bs4 import BeautifulSoupimport refrom selenium.webdriver.chrome.options import Optionsimport csvimport xlwtdef getuid(uid):    url=&#39;https://space.bilibili.com/&#39;+str(uid)    r=requests.get(url,timeout=30)    return r.textdef cutuid(html):    soup=BeautifulSoup(html,&#39;html.parser&#39;)    ls=soup.find_all(&#39;meta&#39;,content=re.compile(&#39;bilibili&#39;))    #获得简介框（因为简介tag包含&#39;bilibili&#39;)    content=str(ls)    small_content=re.split(&#39;，bilibili是国内知名的视频弹幕网站，这里有最及时的动漫新番，最棒的ACG氛围，最有创意的Up主。大家可以在这里找到许多欢乐。&quot; name=&quot;description&quot;&gt;\n&lt;/meta&gt;&#39;,content)    a=small_content[0]    b=re.split(&#39;meta content=&quot;&#39;,a)    c=b[1]    final_content=re.split(&#39;，&#39;,c,1)    name=final_content[0]    return name#获得hololive众人的uid，286700005是holo哥的uiduid_href=&#39;&#39;href=[]driver=webdriver.Firefox()driver.get(&#39;https://space.bilibili.com/&#39;+user+&#39;/fans/follow&#39;)html=driver.page_sourcesoup=BeautifulSoup(html,&#39;html.parser&#39;)tags=soup.find_all(attrs={&#39;href&#39;:re.compile(r&quot;//space.bilibili.com/(\d+)/&quot;)})for tag in tags:    if &#39;href&#39; in tag.attrs:        href+=tag.attrs[&#39;href&#39;]    uid_href=&#39;&#39;.join(href)pattern=re.compile(r&#39;\d+&#39;)uids=pattern.findall(uid_href)uids=list(set(uids))#获得名称name=[]for i in range(0,len(uids)):    html=getuid(uids[i])    name.append(cutuid(html))#获得粉丝数followers=[]for i in range(0,len(uids)):    driver.get(&#39;https://api.bilibili.com/x/relation/stat?vmid=&#39;+uids[i])    html=driver.page_source    soup=BeautifulSoup(html,&#39;html.parser&#39;)    data=soup.find(&#39;div&#39;,id=&#39;json&#39;)    data=data.string    data=data.split(&#39;&quot;follower&quot;:&#39;)    follower=data[-1].split(&#39;}}&#39;)    followers+=follower    followers= [i for i in followers if i != &#39;&#39;]#获得播放量views=&#39;&#39;  for i in range(0,len(uids)):    driver.get(&#39;https://api.bilibili.com/x/space/upstat?mid=&#39;+uids[i])    html=driver.page_source    soup=BeautifulSoup(html,&#39;html.parser&#39;)    data=soup.find(&#39;div&#39;,id=&#39;json&#39;)    data=data.string    data=data.split(&#39;{&quot;code&quot;:0,&quot;message&quot;:&quot;0&quot;,&quot;ttl&quot;:1,&quot;data&quot;:{&quot;archive&quot;:{&quot;view&quot;:&#39;)    data=data[1]    data=data.split(&#39;},&quot;article&quot;&#39;)    view=data[0]+&#39;,&#39;    views+=viewviews=views.split(&#39;,&#39;)print(uids)print(name)print(followers)print(views)#作图from pyecharts import options as optsfrom pyecharts.charts import Barfrom pyecharts.globals import ThemeTypec = (    Bar(init_opts=opts.InitOpts(theme=ThemeType.LIGHT))    .add_xaxis(name)    .add_yaxis(&quot;粉丝数量&quot;, followers)    .add_yaxis(&quot;播放量&quot;, views)    .set_global_opts(        xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=60)),        title_opts=opts.TitleOpts(title=&quot;hololive&quot;, subtitle=&quot;粉丝数和播放量&quot;),    )    .render(&quot;hololive.html&quot;))</code></pre><h4 id><a href="#" class="headerlink" title></a></h4>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>-爬虫 -B站 -数据可视化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>爬取B站弹幕信息制作词云</title>
    <link href="/2020/04/03/%E7%88%AC%E5%8F%96B%E7%AB%99%E5%BC%B9%E5%B9%95%E4%BF%A1%E6%81%AF%E5%88%B6%E4%BD%9C%E8%AF%8D%E4%BA%91/"/>
    <url>/2020/04/03/%E7%88%AC%E5%8F%96B%E7%AB%99%E5%BC%B9%E5%B9%95%E4%BF%A1%E6%81%AF%E5%88%B6%E4%BD%9C%E8%AF%8D%E4%BA%91/</url>
    
    <content type="html"><![CDATA[<h3 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h3><h5 id="获得弹幕"><a href="#获得弹幕" class="headerlink" title="获得弹幕"></a>获得弹幕</h5><pre><code class="python">import reimport requestsimport bs4from bs4 import BeautifulSoup#获取弹幕def getDM(oid):    r=requests.get(&#39;https://api.bilibili.com/x/v1/dm/list.so?oid=&#39;+oid)    r.encoding=r.apparent_encoding    return r.text#截取有效弹幕部分def cutDM(html):    soup=BeautifulSoup(html,&#39;html.parser&#39;)    ls=soup.find_all(&#39;d&#39;)    danmu=&#39;&#39;    for i in ls:        content=&#39;&#39;.join(i.string)        danmu+=content    #content=str(ls)    #pattern=re.compile(&#39;&lt;d.*?&gt;(.*?)&lt;/d&gt;&#39;)    #danmu=pattern.findall(content)    return danmudef saveDM(danmu):    f=open(&#39;danmu.txt&#39;,&#39;wt&#39;,encoding=&#39;utf-8&#39;)    danmu=str(danmu)    f.write(danmu)def main():    oid=input(&#39;请输入oid:&#39;)    html=getDM(oid)    danmu=cutDM(html)    saveDM(danmu)main()</code></pre><h5 id="制作词云"><a href="#制作词云" class="headerlink" title="制作词云"></a>制作词云</h5><pre><code class="python">import wordcloudfrom matplotlib.pyplot import imreadimport jiebatxt=open(&#39;danmu.txt&#39;,&#39;r&#39;,encoding=&#39;UTF-8&#39;).read()ls=jieba.lcut(txt)content=&#39; &#39;.join(ls)print(content)mk=imread(&#39;C:/Users/ASUS/Pictures/sui1.jpg&#39;)w=wordcloud.WordCloud(font_path=&#39;msyh.ttc&#39;,width=700,height=1000,background_color=&#39;white&#39;,mask=mk)w.generate(content)w.to_file(&#39;sui.png&#39;)</code></pre><h3 id="任务分析"><a href="#任务分析" class="headerlink" title="任务分析"></a>任务分析</h3><p>首先爬取弹幕制作词云任务很明显的分为两个部分：数据爬取和数据分析。数据爬取时我们需要爬取B站的弹幕信息，但是由于弹幕信息并非直接显示在当前视频页面的html下，所以我们必须使用’检查‘来寻找存放弹幕信息的xml。爬取好了的弹幕我们需要进行处理，裁取出有效的部分，再进行词频的统计以及词云的制作。</p><h5 id="弹幕爬取"><a href="#弹幕爬取" class="headerlink" title="弹幕爬取"></a>弹幕爬取</h5><p>在这个程序中，我们首先使用requests库进行网页爬取，但是由于这个例子比较简单，你也可以使用python自带的网络爬虫工具来完成。</p><p>由于B站弹幕页面header的编码格式并不是支持中文的utf-8，所以我们要更改页面编码格式，你可以把编码格式手动改为utf-8，也可以将编码格式改成页面实际编码格式。</p><p>然后我们可以使用r.text获得页面的所有信息。如果你还想再看一次的话，使用print()函数。</p><pre><code class="python">import requestsr=requests.get(&#39;https://api.bilibili.com/x/v1/dm/list.so?oid=&#39;+oid)r.encoding=r.apparent_encodinghtml=r.textprint(html)</code></pre><h5 id="弹幕裁取"><a href="#弹幕裁取" class="headerlink" title="弹幕裁取"></a>弹幕裁取</h5><p>在爬取好页面信息html后，我们使用BeautifulSoup库进行html页面的解析。将html解析成beautifulsoup类。</p><pre><code class="python">soup=BeautifulSoup(html,&#39;html.parser&#39;)</code></pre><p>在任务执行前对页面的分析或者刚刚我们用print()函数所看到的页面信息中，我们可以发现：弹幕内容被存放到了d标签中的字符串中。所以我们可以通过soup.find_all()来获得所有d标签。然后我们使用一个for循环获得单个标签，再通过tag.string 来获得b标签的字符串内容，即我们所需要的弹幕内容。</p><pre><code>ls=soup.find_all(&#39;d&#39;)danmu=&#39;&#39;for i in ls:   content=&#39;&#39;.join(i.string)   danmu+=content</code></pre><p>当然，你要是不嫌烦的话，可以按照网上许多教程所说的那样获得d标签的所有内容，然后再用正则表达式截取出弹幕内容。当然这样就比较麻烦，显然辜负了B站程序员们清楚的代码风格。<del>但是这锻炼了你正则表达式的熟练度。</del></p><pre><code class="python">content=str(ls)pattern=re.compile(&#39;&lt;d.*?&gt;(.*?)&lt;/d&gt;&#39;)danmu=pattern.findall(content)</code></pre><h5 id="词云制作"><a href="#词云制作" class="headerlink" title="词云制作"></a>词云制作</h5><p>最后我们需要制作词云，由于B站弹幕绝大部分是中文，我们可以使用jieba库对弹幕内容进行分词。如果你想要更好的分词结果：比如支持日文和其他语言，你可能需要其他的工具支持。</p><pre><code class="python">import jiebatxt=open(&#39;danmu.txt&#39;,&#39;r&#39;,encoding=&#39;UTF-8&#39;).read()ls=jieba.lcut(txt)content=&#39; &#39;.join(ls)     #空格分隔词语，方便下一步词云的制作print(content)            #检查</code></pre><p>分词后我们就可以使用Wordcloud库进行词云制作了。如果你想要制作一个特别的词云，你可能需要mask的支持。mask可以理解为蒙版，可以使你的词云呈现特定的形状。你需要使用matplotlib.pyplot库来读取你的图片mask。最后将词云文件保存，任务完成。最后我们得到的结果如下：<a href="http://q8i78k1ua.bkt.clouddn.com/sui.png" target="_blank" rel="noopener">词云效果</a></p><pre><code class="python">import wordcloudfrom matplotlib.pyplot import imreadmk=imread(&#39;C:/Users/ASUS/Pictures/sui1.jpg&#39;)w=wordcloud.WordCloud(font_path=&#39;msyh.ttc&#39;,width=700,height=1000,background_color=&#39;white&#39;,mask=mk)w.generate(content)w.to_file(&#39;sui.png&#39;)</code></pre><p>当然，这个任务还有很多可以优化的地方，比如我们可以直接通过BV号获得oid，而不用去寻找视频的oid；我们可以批量获得一个用户的所有视频的数据，制作数据量更大的词云；我们还可以支持多语言的分词，设置词表来达到更好的分词效果。有空我会继续更新。</p><h3 id="优化1：直接通过BV号获得oid（4-4完成）"><a href="#优化1：直接通过BV号获得oid（4-4完成）" class="headerlink" title="优化1：直接通过BV号获得oid（4.4完成）"></a>优化1：直接通过BV号获得oid（4.4完成）</h3><p>如果直接使用requests库的get去爬取页面的话，我们无法看到视频的oid，所以为了模拟人真实的行为来获得我们所需要的数据，我们需要使用selenium库来模仿一个浏览器进行操作。</p><pre><code class="python">from selenium import webdriverdriver=webdriver.Firefox()driver.get(&#39;https://www.bilibili.com/video/&#39;+bv)</code></pre><p>上面我们模拟了火狐浏览器对url进行访问，这时候我们就可以做到所见即所得了。</p><p>对视频url进行爬取之后我们需要对我们获得的无比复杂的视频源页面的oid进行分析，具体过程如下：</p><pre><code class="python">soup=BeautifulSoup(html,&#39;html.parser&#39;)content=soup.find(string=re.compile(r&#39;.bilivideo.com/upgcxcode&#39;))a=&#39;&#39;a+=contentb=a.split(&#39;base_url&#39;)c=&#39;&#39;c+=b[0]d=c.split(&#39;upgcxcode&#39;)e=&#39;&#39;e+=d[1]content=e.split(&#39;/&#39;,4)oid=content[3]</code></pre><p>这里的思路就是用split不断进行切割，最后得到视频的oid。</p><p>接下来的步骤就和之前一样了。</p><h3 id="优化2：批量获得一个用户的所有视频的数据（4-4完成）"><a href="#优化2：批量获得一个用户的所有视频的数据（4-4完成）" class="headerlink" title="优化2：批量获得一个用户的所有视频的数据（4.4完成）"></a>优化2：批量获得一个用户的所有视频的数据（4.4完成）</h3><p>想了想很简单，其实优化1和2对之前的我的关键难点就是无法模拟人的操作，在掌握了selenium之后这些难题就迎刃而解了。</p><p>这个优化可以这样实现：</p><p>1.获取用户的uid并访问其空间</p><p>2.获取空间中的视频bv号</p><p>3.沿用优化1的方法</p><h3 id="优化3：更好的分词效果"><a href="#优化3：更好的分词效果" class="headerlink" title="优化3：更好的分词效果"></a>优化3：更好的分词效果</h3>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>-爬虫
-B站</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的博客说明</title>
    <link href="/2020/04/02/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87blog/"/>
    <url>/2020/04/02/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87blog/</url>
    
    <content type="html"><![CDATA[<h3 id="为啥整了这个玩意"><a href="#为啥整了这个玩意" class="headerlink" title="为啥整了这个玩意"></a>为啥整了这个玩意</h3><p>其实说实在的也没有什么原因，在翻关注的up主‘codesheep’的视频时看到了有教怎么用hexo搭建个人博客的。<del>正好我今天也不怎么想学习</del>，于是就整了一个…虽然但是，整这个的过程真的挺麻烦的，如果有感兴趣的也可以去看一下（因为他是macOS系统，所以Windows上有很多操作不一样，建议开着弹幕看）。</p><h3 id="要用这玩意干啥"><a href="#要用这玩意干啥" class="headerlink" title="要用这玩意干啥"></a>要用这玩意干啥</h3><p>毕竟是心血来潮弄的博客，所以具体要做什么也没有很清楚的想法。但是出于不想要和其他平台的功能重复，所以这边基本上是不会发一些随笔之类的，主要会围绕编程、视频剪辑相关的比较偏所谓‘极客’一点的东西。</p><p>目前的想法是每月计划，每周学习总结之类的都会发上来。毕竟要真写纯技术类的我可能要先自我禁言五六个月…</p><h3 id="其他相关"><a href="#其他相关" class="headerlink" title="其他相关"></a>其他相关</h3><p>暂时也没有什么要说的了，どぞ、よろしくお願いします！</p>]]></content>
    
    
    <categories>
      
      <category>-计划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>-生活
-计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/04/02/hello-world/"/>
    <url>/2020/04/02/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
